{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline\n",
    "\n",
    "My goals for this dataset was to extract meaningful features and classify the flight.\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "### Supervised vs Unsuperivsed Learning\n",
    "\n",
    "The first question I asked myself was should I use supervised or unsupervised techinques. To a large extent I like the certaininty of supervised techinque. There are verifiable model metrics that explicitly inform of me my success or failure. But would slapping on some labled really help me understand the true nature of the data? Below is my thought process:\n",
    "\n",
    "Key Advantages of Supervised Learning:\n",
    "\n",
    "- Results are directly interpretable since each class has a known real-world meaning\n",
    "- Can leverage existing domain expertise through the labeling process\n",
    "- Performance can be quantitatively validated against ground truth\n",
    "\n",
    "Key Advantages of Unsupervised Learning:\n",
    "\n",
    "- Can discover novel patterns that weren't previously known or considered\n",
    "- Can analyze the complete dataset without being limited by label availability\n",
    "- Not limited by the potential quality issues or obtuseness of labels\n",
    "\n",
    "An unsupervised learning approach lets the data tell its own story. Rather than forcing the data into predefined boxes, we're letting the model make its own findings, discovering the true nature of contend of the data in ADSB records.\n",
    "\n",
    "### Model Selection\n",
    "\n",
    "Having decided to use unsupervised techinques, I now needed to choose which one(s). I really wanted something that would detect subtle variations in flight traces and that would not only be able to truly process high level data aggregations. At the same time, I want something that was performant or at least could be well optimized given the right hardware. My first priority though was really getting choosing a model that would get into the data, and if the outputs would be that much better I would be willing to make some performance trade-offs. Even though this is an academic project, I always keep model performance in mind because I want to get the most experience possible with models that make sense to deploy on real world problems ata production scale.\n",
    "\n",
    "Here were the options I considered:\n",
    "\n",
    "Traditional Machine Learning Models\n",
    "\n",
    "- Traditional Clustering (K-means/DBSCAN)\n",
    "  - Pros:\n",
    "    - Computationally efficient and easy to implement\n",
    "    - Very interpretable results with clear cluster centroids\n",
    "    - Minimal hyperparameter tuning needed compared to deep learning approaches\n",
    "  - Cons:\n",
    "    - Cannot naturally handle temporal aspects of flight data\n",
    "    - Struggles with variable-density clusters of flight patterns\n",
    "    - No inherent mechanism for anomaly detection\n",
    "- Isolation Forest\n",
    "  - Pros:\n",
    "  - Specifically designed for anomaly detection\n",
    "    - Computationally efficient even with large datasets\n",
    "    - Works well with high-dimensional flight data\n",
    "  - Cons:\n",
    "    - No clustering capability for normal flight patterns\n",
    "    - Cannot capture temporal relationships in data\n",
    "    - Limited interpretability of why something is classified as anomalous\n",
    "\n",
    "Probabilistic Models \n",
    "\n",
    "- Hidden Markov Models (HMMs)\n",
    "  - Pros:\n",
    "    - Naturally models flight phase transitions\n",
    "    - Computationally efficient once trained\n",
    "    - Very interpretable state transitions\n",
    "  - Cons:\n",
    "    - Struggles with continuous, high-dimensional flight data\n",
    "    - Limited ability to detect subtle anomalies\n",
    "    - Can be biased by initial state assumptions\n",
    "\n",
    "Deep Learning Models\n",
    "\n",
    "- Autoencoder + HDBSCAN\n",
    "  - Pros:\n",
    "    - Simultaneously learns normal flight patterns while providing rich anomaly detection through reconstruction error\n",
    "    - Produces interpretable latent space representations that help explain both clusters and anomalies\n",
    "    - Can detect both global pattern deviations and local anomalies (like sudden accelerations) in a single model\n",
    "  - Cons:\n",
    "    - Requires significant tuning of both autoencoder architecture and HDBSCAN parameters\n",
    "    - May overfit to common flight patterns if training data isn't sufficiently diverse\n",
    "    - Computationally intensive during training phase compared to traditional methods\n",
    "\n",
    "- GANs\n",
    "  - Pros:\n",
    "    - Can learn very subtle deviations from normal flight patterns\n",
    "    - Particularly good at handling multimodal distributions in flight behaviors\n",
    "    - Can generate synthetic examples to help validate anomaly detection\n",
    "  - Cons:\n",
    "    - Notoriously difficult to train and achieve stable convergence\n",
    "  - Much higher computational overhead than other approaches\n",
    "    - May suffer from mode collapse, missing important but rare flight patterns\n",
    "\n",
    "- LSTM-based approaches\n",
    "  - Pros:\n",
    "    - Naturally handles temporal dependencies in flight patterns\n",
    "    - Excellent at predicting expected behavior sequences\n",
    "    - Can capture long-term dependencies in flight phases\n",
    "  - Cons:\n",
    "    - Tends to focus on global patterns, potentially missing local anomalies\n",
    "    - Memory requirements scale with sequence length\n",
    "    - Can be biased toward more common flight patterns, potentially normalizing subtle anomalies\n",
    "\n",
    "Although it would probably be interesting to apply all of the models listed above, the becase of the scope of this project (and the fact that I sank so much time extracting and trandorming the data) we are only gong to choose one... and we're going with the Autoencoder + HDBSCAN combination because it uniquely provides both rich anomaly detection capabilities through reconstruction error and effective clustering of normal flight patterns in a single model architecture, while maintaining interpretability through its latent space representations. This approach outperforms other models by simultaneously capturing both global flight patterns and local anomalies (such as unusual accelerations or trajectory deviations), and though it requires more computational resources during training, the quality of insights it provides justifies this tradeoff compared to simpler approaches.\n",
    "\n",
    "### Tools used\n",
    "\n",
    "Before going into the individual models, let's take a look at the core packages doing the work here and talk about why we chose them.\n",
    "\n",
    "- Core Machine Learning Tools:\n",
    "  - PyTorch:\n",
    "    - Implements autoencoder architecture for dimensionality reduction of flight data\n",
    "    - Provides GPU acceleration for training through CUDA integration\n",
    "    - Manages batch processing and gradient optimization through DataLoader\n",
    "    - Generally easier implementation and tuning than Tensorflow for simliar models\n",
    "\n",
    "  - HDBSCAN:\n",
    "    - Performs density-based clustering to identify distinct flight patterns\n",
    "    - Handles noise points and variable-density clusters automatically\n",
    "    - Determines optimal number of clusters through hierarchical density estimation\n",
    "\n",
    "  - Scikit-learn:\n",
    "    - Standardizes features through robust scaling operations\n",
    "    - Removes outliers using statistical methods (z-score analysis)\n",
    "    - Provides consistent preprocessing pipeline for both training and inference\n",
    "\n",
    "- Data Management Tools:\n",
    "  - SQLAlchemy + psycopg2:\n",
    "    - Handles efficient batch retrieval of flight telemetry data\n",
    "    - Maintains connection pooling for concurrent database operations\n",
    "    - Provides ORM interface for complex flight data queries\n",
    "\n",
    "  - Pandas:\n",
    "    - Processes time-series flight data through vectorized operations\n",
    "    - Manages complex feature engineering for altitude and speed metrics\n",
    "    - Handles missing data and temporal alignment of flight records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies \n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML  \n",
    "import IPython.core.getipython as getipython\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "from torch.serialization import add_safe_globals\n",
    "\n",
    "# import model object\n",
    "sys.path.append('../scripts')\n",
    "from _09_autoencoder_training import Autoencoder\n",
    "\n",
    "# Add Autoencoder to safe globals\n",
    "add_safe_globals([Autoencoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder\n",
    "\n",
    "#### Hyperparameter Selection\n",
    "\n",
    "- Input Structure (450 dimensions)\n",
    "  - Represents 9 flight features sampled at 50 timepoints\n",
    "  - Creates temporal sequence for pattern learning\n",
    "  - Requires deeper architecture versus point-in-time features\n",
    "\n",
    "- Network Width (256 → 128 → 64 → 32)\n",
    "  - Progressive quartering preserves temporal relationships\n",
    "  - Width accommodates complex time-series patterns\n",
    "  - Prevents information bottlenecks across 450-dimensional input\n",
    "\n",
    "- ReLU Activation Functions\n",
    "  - Mitigates vanishing gradients across deep architecture\n",
    "  - Enhances learning of temporal patterns\n",
    "  - Maintains non-linearity without sigmoid saturation issues\n",
    "\n",
    "- Encoding Dimension (32)\n",
    "  - Implements ~14:1 compression ratio from 450 input features\n",
    "  - Maintains capacity for temporal pattern variations\n",
    "  - Balances compression against reconstruction accuracy\n",
    "\n",
    "- Batch Size (32)\n",
    "  - Ensures stable gradient updates for temporal sequences\n",
    "  - Optimizes 32GB memory constraint\n",
    "  - Maintains temporal diversity within batches\n",
    "\n",
    "- Training Parameters\n",
    "  - 100k random samples from full dataset\n",
    "  - 60-minute training window with GPU acceleration\n",
    "  - Memory-constrained sample size enables efficient iteration\n",
    "\n",
    "- Training Convergence\n",
    "  - Deeper architecture requires longer training vs previous version\n",
    "  - 60-minute window allows sufficient epochs for temporal pattern learning\n",
    "  - Memory constraints influence convergence trade-offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Model Information ===\n",
      "Model Type: Autoencoder\n",
      "Model Mode: Evaluation\n",
      "\n",
      "=== Architecture Overview ===\n",
      "Encoder Architecture:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=450, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (7): ReLU()\n",
      ")\n",
      "\n",
      "Decoder Architecture:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=256, out_features=450, bias=True)\n",
      ")\n",
      "\n",
      "=== Dimensionality Analysis ===\n",
      "Input Dimension: 450\n",
      "Encoding Dimension: 32\n",
      "Compression Ratio: 14.1x\n",
      "\n",
      "=== Parameter Analysis ===\n",
      "Encoder Parameters: 158,688\n",
      "Decoder Parameters: 159,106\n",
      "Total Parameters: 317,794\n",
      "\n",
      "=== Layer Details ===\n",
      "\n",
      "Layer: encoder.0.weight\n",
      "Shape: [256, 450]\n",
      "Parameters: 115,200\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: 0.0235\n",
      "  Std: 0.3674\n",
      "  Min: -4.4464\n",
      "  Max: 4.1463\n",
      "\n",
      "Layer: encoder.0.bias\n",
      "Shape: [256]\n",
      "Parameters: 256\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: encoder.2.weight\n",
      "Shape: [128, 256]\n",
      "Parameters: 32,768\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0941\n",
      "  Std: 0.2647\n",
      "  Min: -4.2953\n",
      "  Max: 2.1230\n",
      "\n",
      "Layer: encoder.2.bias\n",
      "Shape: [128]\n",
      "Parameters: 128\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: encoder.4.weight\n",
      "Shape: [64, 128]\n",
      "Parameters: 8,192\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0445\n",
      "  Std: 0.1346\n",
      "  Min: -0.9577\n",
      "  Max: 0.8867\n",
      "\n",
      "Layer: encoder.4.bias\n",
      "Shape: [64]\n",
      "Parameters: 64\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: encoder.6.weight\n",
      "Shape: [32, 64]\n",
      "Parameters: 2,048\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0312\n",
      "  Std: 0.1620\n",
      "  Min: -0.7805\n",
      "  Max: 1.3526\n",
      "\n",
      "Layer: encoder.6.bias\n",
      "Shape: [32]\n",
      "Parameters: 32\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: decoder.0.weight\n",
      "Shape: [64, 32]\n",
      "Parameters: 2,048\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0562\n",
      "  Std: 0.1430\n",
      "  Min: -1.2951\n",
      "  Max: 0.4102\n",
      "\n",
      "Layer: decoder.0.bias\n",
      "Shape: [64]\n",
      "Parameters: 64\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: decoder.2.weight\n",
      "Shape: [128, 64]\n",
      "Parameters: 8,192\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0449\n",
      "  Std: 0.1388\n",
      "  Min: -1.5799\n",
      "  Max: 0.6840\n",
      "\n",
      "Layer: decoder.2.bias\n",
      "Shape: [128]\n",
      "Parameters: 128\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: decoder.4.weight\n",
      "Shape: [256, 128]\n",
      "Parameters: 32,768\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0865\n",
      "  Std: 0.3414\n",
      "  Min: -10.1759\n",
      "  Max: 1.5157\n",
      "\n",
      "Layer: decoder.4.bias\n",
      "Shape: [256]\n",
      "Parameters: 256\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: decoder.6.weight\n",
      "Shape: [450, 256]\n",
      "Parameters: 115,200\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: 0.0001\n",
      "  Std: 0.1172\n",
      "  Min: -4.1823\n",
      "  Max: 3.5634\n",
      "\n",
      "Layer: decoder.6.bias\n",
      "Shape: [450]\n",
      "Parameters: 450\n",
      "Data Type: torch.float32\n",
      "\n",
      "=== Hardware Information ===\n",
      "Model Device(s): {device(type='cpu')}\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_path = '../data/_09_autoencoder_training/model.pth'\n",
    "loaded_autoencoder = torch.load(model_path, map_location=torch.device('cpu'), weights_only=False)\n",
    "loaded_autoencoder.eval()\n",
    "\n",
    "print(\"=== Basic Model Information ===\")\n",
    "print(f\"Model Type: {type(loaded_autoencoder).__name__}\")\n",
    "print(f\"Model Mode: {'Training' if loaded_autoencoder.training else 'Evaluation'}\")\n",
    "\n",
    "print(\"\\n=== Architecture Overview ===\")\n",
    "print(\"Encoder Architecture:\")\n",
    "print(loaded_autoencoder.encoder)\n",
    "print(\"\\nDecoder Architecture:\")\n",
    "print(loaded_autoencoder.decoder)\n",
    "\n",
    "print(\"\\n=== Dimensionality Analysis ===\")\n",
    "# Get input/encoding dimensions from the first and last layer of encoder\n",
    "input_dim = next(loaded_autoencoder.encoder.children()).in_features\n",
    "encoding_dim = list(loaded_autoencoder.encoder.children())[-2].out_features  # -2 to skip ReLU\n",
    "print(f\"Input Dimension: {input_dim}\")\n",
    "print(f\"Encoding Dimension: {encoding_dim}\")\n",
    "print(f\"Compression Ratio: {input_dim/encoding_dim:.1f}x\")\n",
    "\n",
    "print(\"\\n=== Parameter Analysis ===\")\n",
    "# Separate encoder and decoder parameters\n",
    "encoder_params = sum(p.numel() for p in loaded_autoencoder.encoder.parameters())\n",
    "decoder_params = sum(p.numel() for p in loaded_autoencoder.decoder.parameters())\n",
    "total_params = encoder_params + decoder_params\n",
    "\n",
    "print(f\"Encoder Parameters: {encoder_params:,}\")\n",
    "print(f\"Decoder Parameters: {decoder_params:,}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "\n",
    "print(\"\\n=== Layer Details ===\")\n",
    "for name, param in loaded_autoencoder.state_dict().items():\n",
    "    if isinstance(param, torch.Tensor):\n",
    "        print(f\"\\nLayer: {name}\")\n",
    "        print(f\"Shape: {list(param.size())}\")\n",
    "        print(f\"Parameters: {param.numel():,}\")\n",
    "        print(f\"Data Type: {param.dtype}\")\n",
    "        # Add basic statistics for weight matrices\n",
    "        if 'weight' in name:\n",
    "            print(f\"Weight Stats:\")\n",
    "            print(f\"  Mean: {param.mean().item():.4f}\")\n",
    "            print(f\"  Std: {param.std().item():.4f}\")\n",
    "            print(f\"  Min: {param.min().item():.4f}\")\n",
    "            print(f\"  Max: {param.max().item():.4f}\")\n",
    "\n",
    "print(\"\\n=== Hardware Information ===\")\n",
    "devices = set(param.device for param in loaded_autoencoder.parameters())\n",
    "print(f\"Model Device(s): {devices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model output data\n",
    "\n",
    "Now lets look at the actual outputs from the autoencoder and go over what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_offset_0</th>\n",
       "      <th>vertical_rate_0</th>\n",
       "      <th>ground_speed_0</th>\n",
       "      <th>heading_0</th>\n",
       "      <th>altitude_0</th>\n",
       "      <th>vertical_accel_0</th>\n",
       "      <th>ground_accel_0</th>\n",
       "      <th>turn_rate_0</th>\n",
       "      <th>climb_descent_accel_0</th>\n",
       "      <th>time_offset_1</th>\n",
       "      <th>...</th>\n",
       "      <th>time_offset_49</th>\n",
       "      <th>vertical_rate_49</th>\n",
       "      <th>ground_speed_49</th>\n",
       "      <th>heading_49</th>\n",
       "      <th>altitude_49</th>\n",
       "      <th>vertical_accel_49</th>\n",
       "      <th>ground_accel_49</th>\n",
       "      <th>turn_rate_49</th>\n",
       "      <th>climb_descent_accel_49</th>\n",
       "      <th>segment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>987231</th>\n",
       "      <td>0.007142</td>\n",
       "      <td>50.109253</td>\n",
       "      <td>546.487183</td>\n",
       "      <td>94.370583</td>\n",
       "      <td>34493.812500</td>\n",
       "      <td>-4.301480</td>\n",
       "      <td>-0.116590</td>\n",
       "      <td>0.684139</td>\n",
       "      <td>-31.687557</td>\n",
       "      <td>17424902.0</td>\n",
       "      <td>...</td>\n",
       "      <td>765742720.0</td>\n",
       "      <td>-51.899387</td>\n",
       "      <td>547.978638</td>\n",
       "      <td>72.161011</td>\n",
       "      <td>35430.289062</td>\n",
       "      <td>57.352501</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>-0.333013</td>\n",
       "      <td>-81.800285</td>\n",
       "      <td>8592900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79954</th>\n",
       "      <td>0.003918</td>\n",
       "      <td>82.439018</td>\n",
       "      <td>460.512634</td>\n",
       "      <td>217.097153</td>\n",
       "      <td>35535.257812</td>\n",
       "      <td>6.474170</td>\n",
       "      <td>0.088270</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>20.345068</td>\n",
       "      <td>7059239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>639985984.0</td>\n",
       "      <td>-110.646332</td>\n",
       "      <td>464.905518</td>\n",
       "      <td>210.165787</td>\n",
       "      <td>35595.960938</td>\n",
       "      <td>-3.423635</td>\n",
       "      <td>-0.129447</td>\n",
       "      <td>-0.084875</td>\n",
       "      <td>-43.646847</td>\n",
       "      <td>9125411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567130</th>\n",
       "      <td>0.007740</td>\n",
       "      <td>637.542297</td>\n",
       "      <td>91.083076</td>\n",
       "      <td>95.346695</td>\n",
       "      <td>245.131027</td>\n",
       "      <td>2.802289</td>\n",
       "      <td>-0.533764</td>\n",
       "      <td>-0.150562</td>\n",
       "      <td>-36.902733</td>\n",
       "      <td>5696532.5</td>\n",
       "      <td>...</td>\n",
       "      <td>463879424.0</td>\n",
       "      <td>91.232872</td>\n",
       "      <td>109.719849</td>\n",
       "      <td>53.798630</td>\n",
       "      <td>3160.060547</td>\n",
       "      <td>16.056448</td>\n",
       "      <td>0.228994</td>\n",
       "      <td>-0.235181</td>\n",
       "      <td>-127.201141</td>\n",
       "      <td>11826840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500891</th>\n",
       "      <td>0.006670</td>\n",
       "      <td>-48.454681</td>\n",
       "      <td>414.664429</td>\n",
       "      <td>270.932648</td>\n",
       "      <td>38325.113281</td>\n",
       "      <td>-25.247885</td>\n",
       "      <td>-0.099923</td>\n",
       "      <td>0.151855</td>\n",
       "      <td>4.844756</td>\n",
       "      <td>18432414.0</td>\n",
       "      <td>...</td>\n",
       "      <td>869229888.0</td>\n",
       "      <td>-95.528175</td>\n",
       "      <td>412.022003</td>\n",
       "      <td>283.591400</td>\n",
       "      <td>38207.257812</td>\n",
       "      <td>-20.732584</td>\n",
       "      <td>-0.146490</td>\n",
       "      <td>0.031765</td>\n",
       "      <td>-38.067490</td>\n",
       "      <td>8862811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55399</th>\n",
       "      <td>0.026402</td>\n",
       "      <td>161.986526</td>\n",
       "      <td>116.810905</td>\n",
       "      <td>62.545231</td>\n",
       "      <td>3702.970947</td>\n",
       "      <td>5.630402</td>\n",
       "      <td>-0.747427</td>\n",
       "      <td>0.962443</td>\n",
       "      <td>-101.030655</td>\n",
       "      <td>4920148.5</td>\n",
       "      <td>...</td>\n",
       "      <td>190356688.0</td>\n",
       "      <td>135.428925</td>\n",
       "      <td>119.363556</td>\n",
       "      <td>238.775909</td>\n",
       "      <td>4430.441406</td>\n",
       "      <td>-74.548874</td>\n",
       "      <td>-0.829505</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>-86.863358</td>\n",
       "      <td>10483710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_offset_0  vertical_rate_0  ground_speed_0   heading_0  \\\n",
       "987231       0.007142        50.109253      546.487183   94.370583   \n",
       "79954        0.003918        82.439018      460.512634  217.097153   \n",
       "567130       0.007740       637.542297       91.083076   95.346695   \n",
       "500891       0.006670       -48.454681      414.664429  270.932648   \n",
       "55399        0.026402       161.986526      116.810905   62.545231   \n",
       "\n",
       "          altitude_0  vertical_accel_0  ground_accel_0  turn_rate_0  \\\n",
       "987231  34493.812500         -4.301480       -0.116590     0.684139   \n",
       "79954   35535.257812          6.474170        0.088270     0.007591   \n",
       "567130    245.131027          2.802289       -0.533764    -0.150562   \n",
       "500891  38325.113281        -25.247885       -0.099923     0.151855   \n",
       "55399    3702.970947          5.630402       -0.747427     0.962443   \n",
       "\n",
       "        climb_descent_accel_0  time_offset_1  ...  time_offset_49  \\\n",
       "987231             -31.687557     17424902.0  ...     765742720.0   \n",
       "79954               20.345068      7059239.0  ...     639985984.0   \n",
       "567130             -36.902733      5696532.5  ...     463879424.0   \n",
       "500891               4.844756     18432414.0  ...     869229888.0   \n",
       "55399             -101.030655      4920148.5  ...     190356688.0   \n",
       "\n",
       "        vertical_rate_49  ground_speed_49  heading_49   altitude_49  \\\n",
       "987231        -51.899387       547.978638   72.161011  35430.289062   \n",
       "79954        -110.646332       464.905518  210.165787  35595.960938   \n",
       "567130         91.232872       109.719849   53.798630   3160.060547   \n",
       "500891        -95.528175       412.022003  283.591400  38207.257812   \n",
       "55399         135.428925       119.363556  238.775909   4430.441406   \n",
       "\n",
       "        vertical_accel_49  ground_accel_49  turn_rate_49  \\\n",
       "987231          57.352501         0.024926     -0.333013   \n",
       "79954           -3.423635        -0.129447     -0.084875   \n",
       "567130          16.056448         0.228994     -0.235181   \n",
       "500891         -20.732584        -0.146490      0.031765   \n",
       "55399          -74.548874        -0.829505      0.026354   \n",
       "\n",
       "        climb_descent_accel_49  segment_id  \n",
       "987231              -81.800285     8592900  \n",
       "79954               -43.646847     9125411  \n",
       "567130             -127.201141    11826840  \n",
       "500891              -38.067490     8862811  \n",
       "55399               -86.863358    10483710  \n",
       "\n",
       "[5 rows x 451 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine outputs\n",
    "df = pd.read_parquet('../data/_11_analysis_conclusions/autoencoder_output_sample.parquet')\n",
    "\n",
    "print(f\"number of rows: {len(df)}\")\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understanding Autoencoder Output\n",
    "  - The output is a \"reconstruction\" of the input data\n",
    "  - Think of it like a very sophisticated game of \"telephone\":\n",
    "    - The autoencoder first compresses the flight data (encoder)\n",
    "    - Then tries to recreate the original data from the compressed version (decoder)\n",
    "    - The output shows how well it recreated each detail\n",
    "  - Reconstruction error measures the difference between:\n",
    "    - What went in (original flight pattern)\n",
    "    - What came out (reconstructed flight pattern)\n",
    "  - Large differences (high reconstruction error) suggest:\n",
    "    - Unusual flight patterns\n",
    "    - Potential anomalies\n",
    "    - Patterns the model hasn't learned well\n",
    "  - Small differences (low reconstruction error) suggest:\n",
    "    - Common flight patterns\n",
    "    - Normal behavior\n",
    "    - Patterns similar to training data\n",
    "\n",
    "- Input Structure (450 dimensions)\n",
    "  - 9 flight parameters: time_offset, vertical_rate, ground_speed, heading, altitude, vertical_accel, ground_accel, turn_rate, climb_descent_accel\n",
    "  - Each parameter sampled across 50 sequential points (9 × 50 = 450 dimensions) \n",
    "  - Creates temporal sequence for learning flight trajectory patterns\n",
    "  - Input preserves chronological relationships in flight behavior\n",
    "\n",
    "- Data Preprocessing\n",
    "  - Input data drawn from global ADS-B flight traces\n",
    "  - Continuous traces segmented into 50-point sequences\n",
    "  - Each sequence represents a flight behavior pattern\n",
    "  - Parameters maintain original units and scaling\n",
    " \n",
    "- Architecture Purpose \n",
    "  - Pattern Recognition: Learn common flight trajectory patterns\n",
    "  - Anomaly Detection: Identify unusual flight behaviors\n",
    "  - Dimensionality Reduction: Compress 450D input into meaningful representation\n",
    "  - Sequence Analysis: Capture temporal patterns in flight data\n",
    "\n",
    "- Output Structure\n",
    "  - Matches input dimensionality (450D)\n",
    "  - Reconstructs full sequence of 50 timepoints\n",
    "  - Preserves all 9 original flight parameters\n",
    "  - Enables comparison between input and reconstructed patterns\n",
    "\n",
    "- Training Approach\n",
    "  - Uses full day of global flight data\n",
    "  - Learns from diverse flight patterns and behaviors\n",
    "  - Captures normal variations in flight trajectories\n",
    "  - Establishes baseline for anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDBSCAN\n",
    "\n",
    "#### Hyperparameters Selection\n",
    "\n",
    "- Min Cluster Size (35)\n",
    "  - Started at 100 (0.1% of original dataset)\n",
    "  - Experimented with extremes (10-100 range)\n",
    "  - Found sweet spot at 35 for 10k sample size\n",
    "  - Large enough to ensure statistical significance\n",
    "  - Small enough to capture distinct flight patterns\n",
    "  - Balances between over-fragmentation (87 clusters) and under-segmentation (3 clusters)\n",
    "  - Aligned with visible trajectory groupings in visualization\n",
    " \n",
    "- Min Samples (4)\n",
    "  - Started conservative at 5\n",
    "  - Tested range from 2 (too fragmented) to 8 (too merged)\n",
    "  - Provides sufficient statistical basis for core points\n",
    "  - Allows detection of natural trajectory groupings\n",
    "  - Controls noise without overly restricting cluster formation\n",
    "  - Works well with normalized high-dimensional flight data\n",
    "\n",
    "- Epsilon (0.25)\n",
    "  - Started conservative at 0.1\n",
    "  - Experimented between 0.1 and 0.4\n",
    "  - Accommodates spatial spread visible in 3D trajectory plots\n",
    "  - Handles normalized data in high-dimensional space\n",
    "  - Connects related trajectories without over-merging\n",
    "  - Balances cluster expansion with pattern distinction\n",
    "\n",
    "- Cluster Selection Method ('eom')\n",
    "  - Maintained 'eom' throughout process\n",
    "  - Well-suited for varying density clusters\n",
    "  - Handles flight patterns of different densities\n",
    "  - More robust to noise than alternative methods\n",
    "  - Provides stable cluster selection\n",
    "\n",
    "- Distance Metric (Euclidean)\n",
    "  - Natural choice for normalized continuous flight data\n",
    "  - Works well in high-dimensional spaces\n",
    "  - Computationally efficient for large datasets\n",
    "  - Appropriate for spatial trajectory patterns\n",
    "\n",
    "##### Supporting Decisions\n",
    "\n",
    "- Data Preprocessing\n",
    "  - StandardScaler normalization\n",
    "  - Outlier removal using z-score method (3 standard deviations)\n",
    "  - 10k sample size for computational efficiency\n",
    "  - Input data: 450 dimensions (9 flight parameters × 50 timepoints)\n",
    "\n",
    "- Tuning Process\n",
    "  - Visualization-driven iteration\n",
    "  - Started conservative, tested extremes\n",
    "  - Found balance between cluster count and noise\n",
    "  - Used domain knowledge of flight patterns\n",
    "  - Iterative refinement based on trajectory visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Type: HDBSCAN\n",
      "Min Cluster Size: 35\n",
      "Cluster Selection Method: eom\n",
      "\n",
      "Number of clusters: 10\n",
      "Number of noise points: 4916\n",
      "Total points: 10000\n",
      "\n",
      "Cluster 0 size: 51\n",
      "\n",
      "Cluster 1 size: 35\n",
      "\n",
      "Cluster 2 size: 46\n",
      "\n",
      "Cluster 3 size: 101\n",
      "\n",
      "Cluster 4 size: 2803\n",
      "\n",
      "Cluster 5 size: 56\n",
      "\n",
      "Cluster 6 size: 35\n",
      "\n",
      "Cluster 7 size: 41\n",
      "\n",
      "Cluster 8 size: 138\n",
      "\n",
      "Cluster 9 size: 1778\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the pickled model\n",
    "with open('../data/_10_clustering/model.pkl', 'rb') as f:\n",
    "    clusterer = pickle.load(f)\n",
    "\n",
    "# Basic model info\n",
    "print(f\"Model Type: {type(clusterer).__name__}\")\n",
    "print(f\"Min Cluster Size: {clusterer.min_cluster_size}\")\n",
    "print(f\"Cluster Selection Method: {clusterer.cluster_selection_method}\")\n",
    "\n",
    "# Clustering results\n",
    "n_clusters = len(np.unique(clusterer.labels_)) - (1 if -1 in clusterer.labels_ else 0)\n",
    "print(f\"\\nNumber of clusters: {n_clusters}\")\n",
    "print(f\"Number of noise points: {np.sum(clusterer.labels_ == -1)}\")\n",
    "print(f\"Total points: {len(clusterer.labels_)}\")\n",
    "\n",
    "# Cluster sizes\n",
    "for label in np.unique(clusterer.labels_[clusterer.labels_ != -1]):\n",
    "    print(f\"\\nCluster {label} size: {np.sum(clusterer.labels_ == label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>is_most_typical</th>\n",
       "      <th>is_most_extreme</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8592900</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9125411</th>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11826840</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8862811</th>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10483710</th>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cluster  is_most_typical  is_most_extreme\n",
       "segment_id                                           \n",
       "8592900           5            False            False\n",
       "9125411          -1            False            False\n",
       "11826840          4            False            False\n",
       "8862811           8            False            False\n",
       "10483710         -1            False            False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Examine outputs\n",
    "\n",
    "# read in sample data\n",
    "df = pd.read_parquet('../data/_10_clustering/results.parquet').set_index('segment_id')\n",
    "\n",
    "print(f\"number of rows: {len(df)}\")\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of our cluster model are much more intutive to interpret than the autoencoder output. For each segment ID we get a cluster label. It is actually possible to generate a ton of cool metrics using the clusters themselves. By looking at the number of points in a cluster, the centrality of 1 point with regard to the cluster centroid, and many more insights. But that is out of scope for today. \n",
    "\n",
    "What we are calculating, is the most \"typical\" and the most \"extreme\" trace within each cluster, and storing it to a boolean value. We define the calcualtions we use and the visualize the most typical and extreme traces in the next notebook. \n",
    "\n",
    "#### Constraints\n",
    "\n",
    "Up until this point I have been able to get over all compute and time restraints by utiliziation tools like connection pooling and parellelization. But with these models I have hit a will. For the autoencoder with GPU acceleration, I was able only able to process 100k rows before hitting system memory contraints. That said, running 45 million data pionts through a nueral network isn't that bad.\n",
    "\n",
    "For my HDSBCAN model, I am currently only able to do a sample of 25k rows. Trying to do a sample of 50k rows, it ran for 8 hours and still didn't complete. I was not able to get the GPU acceleration properly working for HDBSCAN due to dependancy issues.\n",
    "\n",
    "I will discuss more about what I woudl do in the future to resolve these constratints and increase my sample size at the end of the next notebook where I talk about ideas for futrue anaylsis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
