{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline\n",
    "\n",
    "My goals for this dataset was to extract meaningful features and classify the flight.\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "### Supervised vs Unsuperivsed Learning\n",
    "\n",
    "The first question I asked myself was should I use supervised or unsupervised techinques. To a large extent I like the certaininty of supervised techinque. There are verifiable model metrics that explicitly inform of me my success or failure. But would slapping on some labled really help me understand the true nature of the data? Below is my thought process:\n",
    "\n",
    "Key Advantages of Supervised Learning:\n",
    "\n",
    "- Results are directly interpretable since each class has a known real-world meaning\n",
    "- Can leverage existing domain expertise through the labeling process\n",
    "- Performance can be quantitatively validated against ground truth\n",
    "\n",
    "Key Advantages of Unsupervised Learning:\n",
    "\n",
    "- Can discover novel patterns that weren't previously known or considered\n",
    "- Can analyze the complete dataset without being limited by label availability\n",
    "- Not limited by the potential quality issues or obtuseness of labels\n",
    "\n",
    "An unsupervised learning approach lets the data tell its own story. Rather than forcing the data into predefined boxes, we're letting the model make its own findings, discovering the true nature of contend of the data in ADSB records.\n",
    "\n",
    "### Model Selection\n",
    "\n",
    "Having decided to use unsupervised techinques, I now needed to choose which one(s). I really wanted something that would detect subtle variations in flight traces and that would not only be able to truly process high level data aggregations. At the same time, I want something that was performant or at least could be well optimized given the right hardware. My first priority though was really getting choosing a model that would get into the data, and if the outputs would be that much better I would be willing to make some performance trade-offs. Even though this is an academic project, I always keep model performance in mind because I want to get the most experience possible with models that make sense to deploy on real world problems ata production scale.\n",
    "\n",
    "Here were the options I considered:\n",
    "\n",
    "Traditional Machine Learning Models\n",
    "\n",
    "- Traditional Clustering (K-means/DBSCAN)\n",
    "  - Pros:\n",
    "    - Computationally efficient and easy to implement\n",
    "    - Very interpretable results with clear cluster centroids\n",
    "    - Minimal hyperparameter tuning needed compared to deep learning approaches\n",
    "  - Cons:\n",
    "    - Cannot naturally handle temporal aspects of flight data\n",
    "    - Struggles with variable-density clusters of flight patterns\n",
    "    - No inherent mechanism for anomaly detection\n",
    "- Isolation Forest\n",
    "  - Pros:\n",
    "  - Specifically designed for anomaly detection\n",
    "    - Computationally efficient even with large datasets\n",
    "    - Works well with high-dimensional flight data\n",
    "  - Cons:\n",
    "    - No clustering capability for normal flight patterns\n",
    "    - Cannot capture temporal relationships in data\n",
    "    - Limited interpretability of why something is classified as anomalous\n",
    "\n",
    "Probabilistic Models \n",
    "\n",
    "- Hidden Markov Models (HMMs)\n",
    "  - Pros:\n",
    "    - Naturally models flight phase transitions\n",
    "    - Computationally efficient once trained\n",
    "    - Very interpretable state transitions\n",
    "  - Cons:\n",
    "    - Struggles with continuous, high-dimensional flight data\n",
    "    - Limited ability to detect subtle anomalies\n",
    "    - Can be biased by initial state assumptions\n",
    "\n",
    "Deep Learning Models\n",
    "\n",
    "- Autoencoder + HDBSCAN\n",
    "  - Pros:\n",
    "    - Simultaneously learns normal flight patterns while providing rich anomaly detection through reconstruction error\n",
    "    - Produces interpretable latent space representations that help explain both clusters and anomalies\n",
    "    - Can detect both global pattern deviations and local anomalies (like sudden accelerations) in a single model\n",
    "  - Cons:\n",
    "    - Requires significant tuning of both autoencoder architecture and HDBSCAN parameters\n",
    "    - May overfit to common flight patterns if training data isn't sufficiently diverse\n",
    "    - Computationally intensive during training phase compared to traditional methods\n",
    "\n",
    "- GANs\n",
    "  - Pros:\n",
    "    - Can learn very subtle deviations from normal flight patterns\n",
    "    - Particularly good at handling multimodal distributions in flight behaviors\n",
    "    - Can generate synthetic examples to help validate anomaly detection\n",
    "  - Cons:\n",
    "    - Notoriously difficult to train and achieve stable convergence\n",
    "  - Much higher computational overhead than other approaches\n",
    "    - May suffer from mode collapse, missing important but rare flight patterns\n",
    "\n",
    "- LSTM-based approaches\n",
    "  - Pros:\n",
    "    - Naturally handles temporal dependencies in flight patterns\n",
    "    - Excellent at predicting expected behavior sequences\n",
    "    - Can capture long-term dependencies in flight phases\n",
    "  - Cons:\n",
    "    - Tends to focus on global patterns, potentially missing local anomalies\n",
    "    - Memory requirements scale with sequence length\n",
    "    - Can be biased toward more common flight patterns, potentially normalizing subtle anomalies\n",
    "\n",
    "Although it would probably be interesting to apply all of the models listed above, the becase of the scope of this project (and the fact that I sank so much time extracting and trandorming the data) we are only gong to choose one... and we're going with the Autoencoder + HDBSCAN combination because it uniquely provides both rich anomaly detection capabilities through reconstruction error and effective clustering of normal flight patterns in a single model architecture, while maintaining interpretability through its latent space representations. This approach outperforms other models by simultaneously capturing both global flight patterns and local anomalies (such as unusual accelerations or trajectory deviations), and though it requires more computational resources during training, the quality of insights it provides justifies this tradeoff compared to simpler approaches.\n",
    "\n",
    "### Tools used\n",
    "\n",
    "Before going into the individual models, let's take a look at the core packages doing the work here and talk about why we chose them.\n",
    "\n",
    "- Core Machine Learning Tools:\n",
    "  - PyTorch:\n",
    "    - Implements autoencoder architecture for dimensionality reduction of flight data\n",
    "    - Provides GPU acceleration for training through CUDA integration\n",
    "    - Manages batch processing and gradient optimization through DataLoader\n",
    "    - Generally easier implementation and tuning than Tensorflow for simliar models\n",
    "\n",
    "  - HDBSCAN:\n",
    "    - Performs density-based clustering to identify distinct flight patterns\n",
    "    - Handles noise points and variable-density clusters automatically\n",
    "    - Determines optimal number of clusters through hierarchical density estimation\n",
    "\n",
    "  - Scikit-learn:\n",
    "    - Standardizes features through robust scaling operations\n",
    "    - Removes outliers using statistical methods (z-score analysis)\n",
    "    - Provides consistent preprocessing pipeline for both training and inference\n",
    "\n",
    "- Data Management Tools:\n",
    "  - SQLAlchemy + psycopg2:\n",
    "    - Handles efficient batch retrieval of flight telemetry data\n",
    "    - Maintains connection pooling for concurrent database operations\n",
    "    - Provides ORM interface for complex flight data queries\n",
    "\n",
    "  - Pandas:\n",
    "    - Processes time-series flight data through vectorized operations\n",
    "    - Manages complex feature engineering for altitude and speed metrics\n",
    "    - Handles missing data and temporal alignment of flight records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies \n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML  \n",
    "import IPython.core.getipython as getipython\n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "from torch.serialization import add_safe_globals\n",
    "\n",
    "# import model object\n",
    "sys.path.append('../scripts')\n",
    "from _09_autoencoder_training import Autoencoder\n",
    "\n",
    "# Add Autoencoder to safe globals\n",
    "add_safe_globals([Autoencoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparmeter Selection\n",
    "\n",
    "#### Autoencoder\n",
    "\n",
    "Hyperparemeters chosen:\n",
    "\n",
    "- Encoding Dimension (10)\n",
    "  - Implements 3:1 compression ratio from ~30 input features\n",
    "  - Forces autoencoder to learn salient flight patterns while discarding noise\n",
    "  - Provides sufficient dimensions to encode standard flight phases while retaining capacity for pattern variations\n",
    " \n",
    "- Batch Size (32) \n",
    "  - Optimizes GPU memory utilization within 12GB constraint\n",
    "  - Maintains training stability through adequate batch size\n",
    "  - Ensures sufficient sample diversity for flight pattern capture\n",
    " \n",
    "- Network Width Progression (32 → 16 → 10)\n",
    "  - Initial width accommodates ~30 dimensional input space\n",
    "  - Progressive halving prevents information bottlenecks\n",
    "  - Creates efficient information funnel for dimensionality reduction\n",
    " \n",
    "- Epochs (50)\n",
    "  - Appropriate iteration count for 100k sample dataset\n",
    "  - Achieves convergence within 10 minute training window\n",
    "  - Balances pattern learning against overfitting risk given architecture simplicity\n",
    "\n",
    "Potential options for future research:\n",
    "\n",
    "- Encoding Dimension (currently 10)\n",
    "  - Try values: [8, 12, 15]\n",
    "  - Higher dimensions could capture more nuanced flight patterns\n",
    "  - Still maintains efficient compression ratio (2:1 at maximum)\n",
    "  - Worth testing first as most impactful parameter\n",
    "\n",
    "- Network Width Progression (currently 32 → 16 → 10)\n",
    "  - Try values: [64 → 32 → 10] or [48 → 24 → 10]\n",
    "  - Wider initial layers capture more complex feature interactions\n",
    "  - GPU memory constraints allow for this expansion\n",
    "  - Maintains gradual dimensionality reduction principle\n",
    "\n",
    "- Batch Size (currently 32)\n",
    "  - Try values: [64, 128]\n",
    "  - 100k samples and 12GB GPU enable larger batches\n",
    "  - Could improve training stability\n",
    "  - May speed up convergence\n",
    "\n",
    "- Epochs (currently 50)\n",
    "  - Try values: [75, 100]\n",
    "  - Sub-10-minute training allows for more iterations\n",
    "  - Should be tuned last after other parameters\n",
    "  - Monitor validation loss to prevent overfitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Model Information ===\n",
      "Model Type: Autoencoder\n",
      "Model Mode: Evaluation\n",
      "\n",
      "=== Architecture Overview ===\n",
      "Encoder Architecture:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=450, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (7): ReLU()\n",
      ")\n",
      "\n",
      "Decoder Architecture:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=256, out_features=450, bias=True)\n",
      ")\n",
      "\n",
      "=== Dimensionality Analysis ===\n",
      "Input Dimension: 450\n",
      "Encoding Dimension: 32\n",
      "Compression Ratio: 14.1x\n",
      "\n",
      "=== Parameter Analysis ===\n",
      "Encoder Parameters: 158,688\n",
      "Decoder Parameters: 159,106\n",
      "Total Parameters: 317,794\n",
      "\n",
      "=== Layer Details ===\n",
      "\n",
      "Layer: encoder.0.weight\n",
      "Shape: [256, 450]\n",
      "Parameters: 115,200\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: 0.0097\n",
      "  Std: 0.2057\n",
      "  Min: -1.8087\n",
      "  Max: 1.7435\n",
      "\n",
      "Layer: encoder.0.bias\n",
      "Shape: [256]\n",
      "Parameters: 256\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: encoder.2.weight\n",
      "Shape: [128, 256]\n",
      "Parameters: 32,768\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0513\n",
      "  Std: 0.1454\n",
      "  Min: -0.8267\n",
      "  Max: 0.7044\n",
      "\n",
      "Layer: encoder.2.bias\n",
      "Shape: [128]\n",
      "Parameters: 128\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: encoder.4.weight\n",
      "Shape: [64, 128]\n",
      "Parameters: 8,192\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0302\n",
      "  Std: 0.1071\n",
      "  Min: -0.7644\n",
      "  Max: 0.5806\n",
      "\n",
      "Layer: encoder.4.bias\n",
      "Shape: [64]\n",
      "Parameters: 64\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: encoder.6.weight\n",
      "Shape: [32, 64]\n",
      "Parameters: 2,048\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0217\n",
      "  Std: 0.1078\n",
      "  Min: -0.6463\n",
      "  Max: 0.3901\n",
      "\n",
      "Layer: encoder.6.bias\n",
      "Shape: [32]\n",
      "Parameters: 32\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: decoder.0.weight\n",
      "Shape: [64, 32]\n",
      "Parameters: 2,048\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0439\n",
      "  Std: 0.1409\n",
      "  Min: -1.3642\n",
      "  Max: 0.4248\n",
      "\n",
      "Layer: decoder.0.bias\n",
      "Shape: [64]\n",
      "Parameters: 64\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: decoder.2.weight\n",
      "Shape: [128, 64]\n",
      "Parameters: 8,192\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0504\n",
      "  Std: 0.1603\n",
      "  Min: -1.3051\n",
      "  Max: 0.6309\n",
      "\n",
      "Layer: decoder.2.bias\n",
      "Shape: [128]\n",
      "Parameters: 128\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: decoder.4.weight\n",
      "Shape: [256, 128]\n",
      "Parameters: 32,768\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0815\n",
      "  Std: 0.2133\n",
      "  Min: -2.3098\n",
      "  Max: 0.7473\n",
      "\n",
      "Layer: decoder.4.bias\n",
      "Shape: [256]\n",
      "Parameters: 256\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: decoder.6.weight\n",
      "Shape: [450, 256]\n",
      "Parameters: 115,200\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0003\n",
      "  Std: 0.1116\n",
      "  Min: -2.5216\n",
      "  Max: 2.0596\n",
      "\n",
      "Layer: decoder.6.bias\n",
      "Shape: [450]\n",
      "Parameters: 450\n",
      "Data Type: torch.float32\n",
      "\n",
      "=== Hardware Information ===\n",
      "Model Device(s): {device(type='cpu')}\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_path = '../data/_09_autoencoder_training/model.pth'\n",
    "loaded_autoencoder = torch.load(model_path, map_location=torch.device('cpu'), weights_only=False)\n",
    "loaded_autoencoder.eval()\n",
    "\n",
    "print(\"=== Basic Model Information ===\")\n",
    "print(f\"Model Type: {type(loaded_autoencoder).__name__}\")\n",
    "print(f\"Model Mode: {'Training' if loaded_autoencoder.training else 'Evaluation'}\")\n",
    "\n",
    "print(\"\\n=== Architecture Overview ===\")\n",
    "print(\"Encoder Architecture:\")\n",
    "print(loaded_autoencoder.encoder)\n",
    "print(\"\\nDecoder Architecture:\")\n",
    "print(loaded_autoencoder.decoder)\n",
    "\n",
    "print(\"\\n=== Dimensionality Analysis ===\")\n",
    "# Get input/encoding dimensions from the first and last layer of encoder\n",
    "input_dim = next(loaded_autoencoder.encoder.children()).in_features\n",
    "encoding_dim = list(loaded_autoencoder.encoder.children())[-2].out_features  # -2 to skip ReLU\n",
    "print(f\"Input Dimension: {input_dim}\")\n",
    "print(f\"Encoding Dimension: {encoding_dim}\")\n",
    "print(f\"Compression Ratio: {input_dim/encoding_dim:.1f}x\")\n",
    "\n",
    "print(\"\\n=== Parameter Analysis ===\")\n",
    "# Separate encoder and decoder parameters\n",
    "encoder_params = sum(p.numel() for p in loaded_autoencoder.encoder.parameters())\n",
    "decoder_params = sum(p.numel() for p in loaded_autoencoder.decoder.parameters())\n",
    "total_params = encoder_params + decoder_params\n",
    "\n",
    "print(f\"Encoder Parameters: {encoder_params:,}\")\n",
    "print(f\"Decoder Parameters: {decoder_params:,}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "\n",
    "print(\"\\n=== Layer Details ===\")\n",
    "for name, param in loaded_autoencoder.state_dict().items():\n",
    "    if isinstance(param, torch.Tensor):\n",
    "        print(f\"\\nLayer: {name}\")\n",
    "        print(f\"Shape: {list(param.size())}\")\n",
    "        print(f\"Parameters: {param.numel():,}\")\n",
    "        print(f\"Data Type: {param.dtype}\")\n",
    "        # Add basic statistics for weight matrices\n",
    "        if 'weight' in name:\n",
    "            print(f\"Weight Stats:\")\n",
    "            print(f\"  Mean: {param.mean().item():.4f}\")\n",
    "            print(f\"  Std: {param.std().item():.4f}\")\n",
    "            print(f\"  Min: {param.min().item():.4f}\")\n",
    "            print(f\"  Max: {param.max().item():.4f}\")\n",
    "\n",
    "print(\"\\n=== Hardware Information ===\")\n",
    "devices = set(param.device for param in loaded_autoencoder.parameters())\n",
    "print(f\"Model Device(s): {devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this after loading the model\n",
    "for name, param in loaded_autoencoder.named_parameters():\n",
    "    if torch.isnan(param).any():\n",
    "        print(f\"Found NaN in {name}\")\n",
    "        print(f\"Number of NaN values: {torch.isnan(param).sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_offset_0</th>\n",
       "      <th>vertical_rate_0</th>\n",
       "      <th>ground_speed_0</th>\n",
       "      <th>heading_0</th>\n",
       "      <th>altitude_0</th>\n",
       "      <th>vertical_accel_0</th>\n",
       "      <th>ground_accel_0</th>\n",
       "      <th>turn_rate_0</th>\n",
       "      <th>climb_descent_accel_0</th>\n",
       "      <th>time_offset_1</th>\n",
       "      <th>...</th>\n",
       "      <th>climb_descent_accel_48</th>\n",
       "      <th>time_offset_49</th>\n",
       "      <th>vertical_rate_49</th>\n",
       "      <th>ground_speed_49</th>\n",
       "      <th>heading_49</th>\n",
       "      <th>altitude_49</th>\n",
       "      <th>vertical_accel_49</th>\n",
       "      <th>ground_accel_49</th>\n",
       "      <th>turn_rate_49</th>\n",
       "      <th>climb_descent_accel_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.012232</td>\n",
       "      <td>124.757225</td>\n",
       "      <td>134.117218</td>\n",
       "      <td>12.111102</td>\n",
       "      <td>5577.511719</td>\n",
       "      <td>34.774097</td>\n",
       "      <td>0.335732</td>\n",
       "      <td>0.396386</td>\n",
       "      <td>-84.265472</td>\n",
       "      <td>6164319.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.870296</td>\n",
       "      <td>233804160.0</td>\n",
       "      <td>308.362976</td>\n",
       "      <td>111.932350</td>\n",
       "      <td>37.655682</td>\n",
       "      <td>6900.161133</td>\n",
       "      <td>-5.082521</td>\n",
       "      <td>0.681807</td>\n",
       "      <td>0.474065</td>\n",
       "      <td>10.336171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.030383</td>\n",
       "      <td>-68.539017</td>\n",
       "      <td>126.066704</td>\n",
       "      <td>186.507965</td>\n",
       "      <td>983.882690</td>\n",
       "      <td>-92.514633</td>\n",
       "      <td>0.647648</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>421.749451</td>\n",
       "      <td>2808257.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.835022</td>\n",
       "      <td>317216096.0</td>\n",
       "      <td>528.139709</td>\n",
       "      <td>92.318825</td>\n",
       "      <td>130.666245</td>\n",
       "      <td>3655.735107</td>\n",
       "      <td>-13.044754</td>\n",
       "      <td>2.151199</td>\n",
       "      <td>0.144945</td>\n",
       "      <td>-34.874584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.007091</td>\n",
       "      <td>1102.480713</td>\n",
       "      <td>117.209953</td>\n",
       "      <td>139.448792</td>\n",
       "      <td>906.564331</td>\n",
       "      <td>9.117163</td>\n",
       "      <td>0.594191</td>\n",
       "      <td>0.493442</td>\n",
       "      <td>30.539162</td>\n",
       "      <td>3730686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.252929</td>\n",
       "      <td>241445504.0</td>\n",
       "      <td>730.908630</td>\n",
       "      <td>138.762924</td>\n",
       "      <td>157.216064</td>\n",
       "      <td>6617.499023</td>\n",
       "      <td>10.617360</td>\n",
       "      <td>0.277255</td>\n",
       "      <td>0.033558</td>\n",
       "      <td>-12.854604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.051130</td>\n",
       "      <td>1219.875610</td>\n",
       "      <td>129.229675</td>\n",
       "      <td>115.401993</td>\n",
       "      <td>309.570190</td>\n",
       "      <td>-26.887356</td>\n",
       "      <td>0.603296</td>\n",
       "      <td>0.232426</td>\n",
       "      <td>129.291153</td>\n",
       "      <td>4967545.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.795601</td>\n",
       "      <td>369166272.0</td>\n",
       "      <td>906.119263</td>\n",
       "      <td>138.388229</td>\n",
       "      <td>107.378693</td>\n",
       "      <td>9967.729492</td>\n",
       "      <td>1.227274</td>\n",
       "      <td>0.898422</td>\n",
       "      <td>0.199884</td>\n",
       "      <td>-35.445938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.002325</td>\n",
       "      <td>1490.529785</td>\n",
       "      <td>180.119324</td>\n",
       "      <td>90.258659</td>\n",
       "      <td>5673.443359</td>\n",
       "      <td>11.089612</td>\n",
       "      <td>-0.178722</td>\n",
       "      <td>0.441372</td>\n",
       "      <td>-32.685139</td>\n",
       "      <td>8447223.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.297771</td>\n",
       "      <td>444908992.0</td>\n",
       "      <td>639.262329</td>\n",
       "      <td>236.004242</td>\n",
       "      <td>165.654724</td>\n",
       "      <td>14742.404297</td>\n",
       "      <td>-16.234608</td>\n",
       "      <td>-0.636310</td>\n",
       "      <td>-0.559497</td>\n",
       "      <td>-2.385418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_offset_0  vertical_rate_0  ground_speed_0   heading_0  \\\n",
       "segment_id                                                               \n",
       "41              -0.012232       124.757225      134.117218   12.111102   \n",
       "42              -0.030383       -68.539017      126.066704  186.507965   \n",
       "43              -0.007091      1102.480713      117.209953  139.448792   \n",
       "49              -0.051130      1219.875610      129.229675  115.401993   \n",
       "44              -0.002325      1490.529785      180.119324   90.258659   \n",
       "\n",
       "             altitude_0  vertical_accel_0  ground_accel_0  turn_rate_0  \\\n",
       "segment_id                                                               \n",
       "41          5577.511719         34.774097        0.335732     0.396386   \n",
       "42           983.882690        -92.514633        0.647648     0.030459   \n",
       "43           906.564331          9.117163        0.594191     0.493442   \n",
       "49           309.570190        -26.887356        0.603296     0.232426   \n",
       "44          5673.443359         11.089612       -0.178722     0.441372   \n",
       "\n",
       "            climb_descent_accel_0  time_offset_1  ...  climb_descent_accel_48  \\\n",
       "segment_id                                        ...                           \n",
       "41                     -84.265472      6164319.0  ...                9.870296   \n",
       "42                     421.749451      2808257.5  ...              -34.835022   \n",
       "43                      30.539162      3730686.5  ...              -13.252929   \n",
       "49                     129.291153      4967545.5  ...              -35.795601   \n",
       "44                     -32.685139      8447223.0  ...               -2.297771   \n",
       "\n",
       "            time_offset_49  vertical_rate_49  ground_speed_49  heading_49  \\\n",
       "segment_id                                                                  \n",
       "41             233804160.0        308.362976       111.932350   37.655682   \n",
       "42             317216096.0        528.139709        92.318825  130.666245   \n",
       "43             241445504.0        730.908630       138.762924  157.216064   \n",
       "49             369166272.0        906.119263       138.388229  107.378693   \n",
       "44             444908992.0        639.262329       236.004242  165.654724   \n",
       "\n",
       "             altitude_49  vertical_accel_49  ground_accel_49  turn_rate_49  \\\n",
       "segment_id                                                                   \n",
       "41           6900.161133          -5.082521         0.681807      0.474065   \n",
       "42           3655.735107         -13.044754         2.151199      0.144945   \n",
       "43           6617.499023          10.617360         0.277255      0.033558   \n",
       "49           9967.729492           1.227274         0.898422      0.199884   \n",
       "44          14742.404297         -16.234608        -0.636310     -0.559497   \n",
       "\n",
       "            climb_descent_accel_49  \n",
       "segment_id                          \n",
       "41                       10.336171  \n",
       "42                      -34.874584  \n",
       "43                      -12.854604  \n",
       "49                      -35.445938  \n",
       "44                       -2.385418  \n",
       "\n",
       "[5 rows x 450 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Examine outputs\n",
    "\n",
    "# read in sample data\n",
    "df = pd.read_parquet('../data/_09_autoencoder_training/results.parquet').set_index('segment_id')\n",
    "\n",
    "print(f\"number of rows: {len(df)}\")\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDBScan\n",
    "\n",
    "Hyperparameters Chosen\n",
    "\n",
    "- Min Cluster Size (100)\n",
    "  - Currently represents ~0.1% of total dataset (100k samples)\n",
    "  - Initial choice targeted approximately 10 clusters\n",
    "  - Consider increasing to 250-500 for more robust clusters\n",
    "  - Larger clusters would better represent major flight patterns\n",
    "  \n",
    "- Min Samples (5)\n",
    "  - Conservative choice for noise detection\n",
    "  - Sufficient for statistical significance without being too restrictive\n",
    "  - Appropriate for normalized 10-dimensional space\n",
    "  - Balances between noise sensitivity and cluster stability\n",
    "\n",
    "- Epsilon (0.1)\n",
    "  - Suitable for normalized data in 10-dimensional space\n",
    "  - Conservative choice for allowing cluster expansion\n",
    "  - Works well with normalized autoencoder outputs\n",
    "  - Prevents excessive cluster merging\n",
    "\n",
    "- Euclidean Distance (metric choice)\n",
    "  - Natural choice for normalized, continuous flight data\n",
    "  - Performs well in moderate-dimensional spaces (10D)\n",
    "  - Computationally efficient for large datasets\n",
    "  - Intuitive distance measure for spatial patterns\n",
    "\n",
    "- EOM Cluster Selection\n",
    "  - Better than leaf for handling varying density clusters\n",
    "  - Well-suited for flight patterns that may have different densities\n",
    "  - More robust to noise than alternative methods\n",
    "  - Good at finding clusters of varying sizes\n",
    "\n",
    "Potential options for future research:\n",
    "\n",
    "- Min Cluster Size (currently 100)\n",
    "  - Try values: [250, 500, 750]\n",
    "  - Larger clusters would better represent major flight patterns\n",
    "  - Could reduce noise sensitivity\n",
    "  - May identify more stable, interpretable patterns\n",
    "\n",
    "- Min Samples (currently 5)\n",
    "  - Keep as is\n",
    "  - Well-tuned for current implementation\n",
    "  - Change only if noise sensitivity needs adjustment\n",
    "\n",
    "- Epsilon (currently 0.1)\n",
    "  - Keep as is\n",
    "  - Works well with normalized data\n",
    "  - Change only if cluster boundaries need adjustment\n",
    "\n",
    "- Alternative Metrics to Consider\n",
    "  - Cosine similarity for direction-based patterns\n",
    "  - Manhattan distance for computational efficiency\n",
    "  - Keep Euclidean as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/your/hdbscan_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the pickled model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath/to/your/hdbscan_model.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m     clusterer \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Basic model info\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jpeck\\py\\ADSB_classification\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/your/hdbscan_model.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the pickled model\n",
    "with open('path/to/your/hdbscan_model.pkl', 'rb') as f:\n",
    "    clusterer = pickle.load(f)\n",
    "\n",
    "# Basic model info\n",
    "print(f\"Model Type: {type(clusterer).__name__}\")\n",
    "print(f\"Min Cluster Size: {clusterer.min_cluster_size}\")\n",
    "print(f\"Cluster Selection Method: {clusterer.cluster_selection_method}\")\n",
    "\n",
    "# Clustering results\n",
    "n_clusters = len(np.unique(clusterer.labels_)) - (1 if -1 in clusterer.labels_ else 0)\n",
    "print(f\"\\nNumber of clusters: {n_clusters}\")\n",
    "print(f\"Number of noise points: {np.sum(clusterer.labels_ == -1)}\")\n",
    "print(f\"Total points: {len(clusterer.labels_)}\")\n",
    "\n",
    "# Cluster sizes\n",
    "for label in np.unique(clusterer.labels_[clusterer.labels_ != -1]):\n",
    "    print(f\"\\nCluster {label} size: {np.sum(clusterer.labels_ == label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a peak at the final data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
