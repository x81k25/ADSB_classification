{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline\n",
    "\n",
    "My goals for this dataset was to extract meaningful features and classify the flight.\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "### Supervised vs Unsuperivsed Learning\n",
    "\n",
    "The first question I asked myself was should I use supervised or unsupervised techinques. To a large extent I like the certaininty of supervised techinque. There are verifiable model metrics that explicitly inform of me my success or failure. But would slapping on some labled really help me understand the true nature of the data? Below is my thought process:\n",
    "\n",
    "Key Advantages of Supervised Learning:\n",
    "\n",
    "- Results are directly interpretable since each class has a known real-world meaning\n",
    "- Can leverage existing domain expertise through the labeling process\n",
    "- Performance can be quantitatively validated against ground truth\n",
    "\n",
    "Key Advantages of Unsupervised Learning:\n",
    "\n",
    "- Can discover novel patterns that weren't previously known or considered\n",
    "- Can analyze the complete dataset without being limited by label availability\n",
    "- Not limited by the potential quality issues or obtuseness of labels\n",
    "\n",
    "An unsupervised learning approach lets the data tell its own story. Rather than forcing the data into predefined boxes, we're letting the model make its own findings, discovering the true nature of contend of the data in ADSB records.\n",
    "\n",
    "### Model Selection\n",
    "\n",
    "Having decided to use unsupervised techinques, I now needed to choose which one(s). I really wanted something that would detect subtle variations in flight traces and that would not only be able to truly process high level data aggregations. At the same time, I want something that was performant or at least could be well optimized given the right hardware. My first priority though was really getting choosing a model that would get into the data, and if the outputs would be that much better I would be willing to make some performance trade-offs. Even though this is an academic project, I always keep model performance in mind because I want to get the most experience possible with models that make sense to deploy on real world problems ata production scale.\n",
    "\n",
    "Here were the options I considered:\n",
    "\n",
    "Traditional Machine Learning Models\n",
    "\n",
    "- Traditional Clustering (K-means/DBSCAN)\n",
    "  - Pros:\n",
    "    - Computationally efficient and easy to implement\n",
    "    - Very interpretable results with clear cluster centroids\n",
    "    - Minimal hyperparameter tuning needed compared to deep learning approaches\n",
    "  - Cons:\n",
    "    - Cannot naturally handle temporal aspects of flight data\n",
    "    - Struggles with variable-density clusters of flight patterns\n",
    "    - No inherent mechanism for anomaly detection\n",
    "- Isolation Forest\n",
    "  - Pros:\n",
    "  - Specifically designed for anomaly detection\n",
    "    - Computationally efficient even with large datasets\n",
    "    - Works well with high-dimensional flight data\n",
    "  - Cons:\n",
    "    - No clustering capability for normal flight patterns\n",
    "    - Cannot capture temporal relationships in data\n",
    "    - Limited interpretability of why something is classified as anomalous\n",
    "\n",
    "Probabilistic Models \n",
    "\n",
    "- Hidden Markov Models (HMMs)\n",
    "  - Pros:\n",
    "    - Naturally models flight phase transitions\n",
    "    - Computationally efficient once trained\n",
    "    - Very interpretable state transitions\n",
    "  - Cons:\n",
    "    - Struggles with continuous, high-dimensional flight data\n",
    "    - Limited ability to detect subtle anomalies\n",
    "    - Can be biased by initial state assumptions\n",
    "\n",
    "Deep Learning Models\n",
    "\n",
    "- Autoencoder + HDBSCAN\n",
    "  - Pros:\n",
    "    - Simultaneously learns normal flight patterns while providing rich anomaly detection through reconstruction error\n",
    "    - Produces interpretable latent space representations that help explain both clusters and anomalies\n",
    "    - Can detect both global pattern deviations and local anomalies (like sudden accelerations) in a single model\n",
    "  - Cons:\n",
    "    - Requires significant tuning of both autoencoder architecture and HDBSCAN parameters\n",
    "    - May overfit to common flight patterns if training data isn't sufficiently diverse\n",
    "    - Computationally intensive during training phase compared to traditional methods\n",
    "\n",
    "- GANs\n",
    "  - Pros:\n",
    "    - Can learn very subtle deviations from normal flight patterns\n",
    "    - Particularly good at handling multimodal distributions in flight behaviors\n",
    "    - Can generate synthetic examples to help validate anomaly detection\n",
    "  - Cons:\n",
    "    - Notoriously difficult to train and achieve stable convergence\n",
    "  - Much higher computational overhead than other approaches\n",
    "    - May suffer from mode collapse, missing important but rare flight patterns\n",
    "\n",
    "- LSTM-based approaches\n",
    "  - Pros:\n",
    "    - Naturally handles temporal dependencies in flight patterns\n",
    "    - Excellent at predicting expected behavior sequences\n",
    "    - Can capture long-term dependencies in flight phases\n",
    "  - Cons:\n",
    "    - Tends to focus on global patterns, potentially missing local anomalies\n",
    "    - Memory requirements scale with sequence length\n",
    "    - Can be biased toward more common flight patterns, potentially normalizing subtle anomalies\n",
    "\n",
    "Although it would probably be interesting to apply all of the models listed above, the becase of the scope of this project (and the fact that I sank so much time extracting and trandorming the data) we are only gong to choose one... and we're going with the Autoencoder + HDBSCAN combination because it uniquely provides both rich anomaly detection capabilities through reconstruction error and effective clustering of normal flight patterns in a single model architecture, while maintaining interpretability through its latent space representations. This approach outperforms other models by simultaneously capturing both global flight patterns and local anomalies (such as unusual accelerations or trajectory deviations), and though it requires more computational resources during training, the quality of insights it provides justifies this tradeoff compared to simpler approaches.\n",
    "\n",
    "### Tools used\n",
    "\n",
    "Before going into the individual models, let's take a look at the core packages doing the work here and talk about why we chose them.\n",
    "\n",
    "- Core Machine Learning Tools:\n",
    "  - PyTorch:\n",
    "    - Implements autoencoder architecture for dimensionality reduction of flight data\n",
    "    - Provides GPU acceleration for training through CUDA integration\n",
    "    - Manages batch processing and gradient optimization through DataLoader\n",
    "    - Generally easier implementation and tuning than Tensorflow for simliar models\n",
    "\n",
    "  - HDBSCAN:\n",
    "    - Performs density-based clustering to identify distinct flight patterns\n",
    "    - Handles noise points and variable-density clusters automatically\n",
    "    - Determines optimal number of clusters through hierarchical density estimation\n",
    "\n",
    "  - Scikit-learn:\n",
    "    - Standardizes features through robust scaling operations\n",
    "    - Removes outliers using statistical methods (z-score analysis)\n",
    "    - Provides consistent preprocessing pipeline for both training and inference\n",
    "\n",
    "- Data Management Tools:\n",
    "  - SQLAlchemy + psycopg2:\n",
    "    - Handles efficient batch retrieval of flight telemetry data\n",
    "    - Maintains connection pooling for concurrent database operations\n",
    "    - Provides ORM interface for complex flight data queries\n",
    "\n",
    "  - Pandas:\n",
    "    - Processes time-series flight data through vectorized operations\n",
    "    - Manages complex feature engineering for altitude and speed metrics\n",
    "    - Handles missing data and temporal alignment of flight records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies \n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML  \n",
    "from IPython.display import Image\n",
    "import IPython.core.getipython as getipython\n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "from torch.serialization import add_safe_globals\n",
    "\n",
    "# import model object\n",
    "sys.path.append('../scripts')\n",
    "from _09_autoencoder_training import Autoencoder\n",
    "\n",
    "# Add Autoencoder to safe globals\n",
    "add_safe_globals([Autoencoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          10,
          11,
          12,
          13
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Test Plot"
        },
        "xaxis": {
         "title": {
          "text": "X Axis"
         }
        },
        "yaxis": {
         "title": {
          "text": "Y Axis"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Function to create and show plot that works in both environments\n",
    "def create_plot():\n",
    "    # Create figure\n",
    "    fig = go.Figure(data=go.Scatter(x=[1, 2, 3, 4], y=[10, 11, 12, 13]))\n",
    "    \n",
    "    fig.update_layout(title='Test Plot', \n",
    "                     xaxis_title='X Axis',\n",
    "                     yaxis_title='Y Axis')\n",
    "    \n",
    "    # For VSCode development\n",
    "    if 'vscode' in pio.renderers.default:\n",
    "        pio.renderers.default = \"vscode\"\n",
    "    # For notebook/HTML export\n",
    "    else:\n",
    "        pio.renderers.default = \"notebook\"\n",
    "    \n",
    "    # Save static HTML version alongside\n",
    "    fig.write_html(\"test_plot.html\", \n",
    "                   include_plotlyjs=True,\n",
    "                   full_html=False)\n",
    "    \n",
    "    # Show interactive version\n",
    "    fig.show()\n",
    "\n",
    "# Run the function\n",
    "create_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"test_plot.html\" width=\"100%\" height=\"600\" frameborder=\"0\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparmeter Selection\n",
    "\n",
    "#### Autoencoder\n",
    "\n",
    "Hyperparemeters chosen:\n",
    "\n",
    "- Encoding Dimension (10)\n",
    "  - Implements 3:1 compression ratio from ~30 input features\n",
    "  - Forces autoencoder to learn salient flight patterns while discarding noise\n",
    "  - Provides sufficient dimensions to encode standard flight phases while retaining capacity for pattern variations\n",
    " \n",
    "- Batch Size (32) \n",
    "  - Optimizes GPU memory utilization within 12GB constraint\n",
    "  - Maintains training stability through adequate batch size\n",
    "  - Ensures sufficient sample diversity for flight pattern capture\n",
    " \n",
    "- Network Width Progression (32 → 16 → 10)\n",
    "  - Initial width accommodates ~30 dimensional input space\n",
    "  - Progressive halving prevents information bottlenecks\n",
    "  - Creates efficient information funnel for dimensionality reduction\n",
    " \n",
    "- Epochs (50)\n",
    "  - Appropriate iteration count for 100k sample dataset\n",
    "  - Achieves convergence within 10 minute training window\n",
    "  - Balances pattern learning against overfitting risk given architecture simplicity\n",
    "\n",
    "Potential options for future research:\n",
    "\n",
    "- Encoding Dimension (currently 10)\n",
    "  - Try values: [8, 12, 15]\n",
    "  - Higher dimensions could capture more nuanced flight patterns\n",
    "  - Still maintains efficient compression ratio (2:1 at maximum)\n",
    "  - Worth testing first as most impactful parameter\n",
    "\n",
    "- Network Width Progression (currently 32 → 16 → 10)\n",
    "  - Try values: [64 → 32 → 10] or [48 → 24 → 10]\n",
    "  - Wider initial layers capture more complex feature interactions\n",
    "  - GPU memory constraints allow for this expansion\n",
    "  - Maintains gradual dimensionality reduction principle\n",
    "\n",
    "- Batch Size (currently 32)\n",
    "  - Try values: [64, 128]\n",
    "  - 100k samples and 12GB GPU enable larger batches\n",
    "  - Could improve training stability\n",
    "  - May speed up convergence\n",
    "\n",
    "- Epochs (currently 50)\n",
    "  - Try values: [75, 100]\n",
    "  - Sub-10-minute training allows for more iterations\n",
    "  - Should be tuned last after other parameters\n",
    "  - Monitor validation loss to prevent overfitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Model Information ===\n",
      "Model Type: Autoencoder\n",
      "Model Mode: Evaluation\n",
      "\n",
      "=== Architecture Overview ===\n",
      "Encoder Architecture:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=450, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (7): ReLU()\n",
      ")\n",
      "\n",
      "Decoder Architecture:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=256, out_features=450, bias=True)\n",
      ")\n",
      "\n",
      "=== Dimensionality Analysis ===\n",
      "Input Dimension: 450\n",
      "Encoding Dimension: 32\n",
      "Compression Ratio: 14.1x\n",
      "\n",
      "=== Parameter Analysis ===\n",
      "Encoder Parameters: 158,688\n",
      "Decoder Parameters: 159,106\n",
      "Total Parameters: 317,794\n",
      "\n",
      "=== Layer Details ===\n",
      "\n",
      "Layer: encoder.0.weight\n",
      "Shape: [256, 450]\n",
      "Parameters: 115,200\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: 0.0235\n",
      "  Std: 0.3674\n",
      "  Min: -4.4464\n",
      "  Max: 4.1463\n",
      "\n",
      "Layer: encoder.0.bias\n",
      "Shape: [256]\n",
      "Parameters: 256\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: encoder.2.weight\n",
      "Shape: [128, 256]\n",
      "Parameters: 32,768\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0941\n",
      "  Std: 0.2647\n",
      "  Min: -4.2953\n",
      "  Max: 2.1230\n",
      "\n",
      "Layer: encoder.2.bias\n",
      "Shape: [128]\n",
      "Parameters: 128\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: encoder.4.weight\n",
      "Shape: [64, 128]\n",
      "Parameters: 8,192\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0445\n",
      "  Std: 0.1346\n",
      "  Min: -0.9577\n",
      "  Max: 0.8867\n",
      "\n",
      "Layer: encoder.4.bias\n",
      "Shape: [64]\n",
      "Parameters: 64\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: encoder.6.weight\n",
      "Shape: [32, 64]\n",
      "Parameters: 2,048\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0312\n",
      "  Std: 0.1620\n",
      "  Min: -0.7805\n",
      "  Max: 1.3526\n",
      "\n",
      "Layer: encoder.6.bias\n",
      "Shape: [32]\n",
      "Parameters: 32\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: decoder.0.weight\n",
      "Shape: [64, 32]\n",
      "Parameters: 2,048\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0562\n",
      "  Std: 0.1430\n",
      "  Min: -1.2951\n",
      "  Max: 0.4102\n",
      "\n",
      "Layer: decoder.0.bias\n",
      "Shape: [64]\n",
      "Parameters: 64\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: decoder.2.weight\n",
      "Shape: [128, 64]\n",
      "Parameters: 8,192\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0449\n",
      "  Std: 0.1388\n",
      "  Min: -1.5799\n",
      "  Max: 0.6840\n",
      "\n",
      "Layer: decoder.2.bias\n",
      "Shape: [128]\n",
      "Parameters: 128\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: decoder.4.weight\n",
      "Shape: [256, 128]\n",
      "Parameters: 32,768\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: -0.0865\n",
      "  Std: 0.3414\n",
      "  Min: -10.1759\n",
      "  Max: 1.5157\n",
      "\n",
      "Layer: decoder.4.bias\n",
      "Shape: [256]\n",
      "Parameters: 256\n",
      "Data Type: torch.float32\n",
      "\n",
      "Layer: decoder.6.weight\n",
      "Shape: [450, 256]\n",
      "Parameters: 115,200\n",
      "Data Type: torch.float32\n",
      "Weight Stats:\n",
      "  Mean: 0.0001\n",
      "  Std: 0.1172\n",
      "  Min: -4.1823\n",
      "  Max: 3.5634\n",
      "\n",
      "Layer: decoder.6.bias\n",
      "Shape: [450]\n",
      "Parameters: 450\n",
      "Data Type: torch.float32\n",
      "\n",
      "=== Hardware Information ===\n",
      "Model Device(s): {device(type='cpu')}\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_path = '../data/_09_autoencoder_training/model.pth'\n",
    "loaded_autoencoder = torch.load(model_path, map_location=torch.device('cpu'), weights_only=False)\n",
    "loaded_autoencoder.eval()\n",
    "\n",
    "print(\"=== Basic Model Information ===\")\n",
    "print(f\"Model Type: {type(loaded_autoencoder).__name__}\")\n",
    "print(f\"Model Mode: {'Training' if loaded_autoencoder.training else 'Evaluation'}\")\n",
    "\n",
    "print(\"\\n=== Architecture Overview ===\")\n",
    "print(\"Encoder Architecture:\")\n",
    "print(loaded_autoencoder.encoder)\n",
    "print(\"\\nDecoder Architecture:\")\n",
    "print(loaded_autoencoder.decoder)\n",
    "\n",
    "print(\"\\n=== Dimensionality Analysis ===\")\n",
    "# Get input/encoding dimensions from the first and last layer of encoder\n",
    "input_dim = next(loaded_autoencoder.encoder.children()).in_features\n",
    "encoding_dim = list(loaded_autoencoder.encoder.children())[-2].out_features  # -2 to skip ReLU\n",
    "print(f\"Input Dimension: {input_dim}\")\n",
    "print(f\"Encoding Dimension: {encoding_dim}\")\n",
    "print(f\"Compression Ratio: {input_dim/encoding_dim:.1f}x\")\n",
    "\n",
    "print(\"\\n=== Parameter Analysis ===\")\n",
    "# Separate encoder and decoder parameters\n",
    "encoder_params = sum(p.numel() for p in loaded_autoencoder.encoder.parameters())\n",
    "decoder_params = sum(p.numel() for p in loaded_autoencoder.decoder.parameters())\n",
    "total_params = encoder_params + decoder_params\n",
    "\n",
    "print(f\"Encoder Parameters: {encoder_params:,}\")\n",
    "print(f\"Decoder Parameters: {decoder_params:,}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "\n",
    "print(\"\\n=== Layer Details ===\")\n",
    "for name, param in loaded_autoencoder.state_dict().items():\n",
    "    if isinstance(param, torch.Tensor):\n",
    "        print(f\"\\nLayer: {name}\")\n",
    "        print(f\"Shape: {list(param.size())}\")\n",
    "        print(f\"Parameters: {param.numel():,}\")\n",
    "        print(f\"Data Type: {param.dtype}\")\n",
    "        # Add basic statistics for weight matrices\n",
    "        if 'weight' in name:\n",
    "            print(f\"Weight Stats:\")\n",
    "            print(f\"  Mean: {param.mean().item():.4f}\")\n",
    "            print(f\"  Std: {param.std().item():.4f}\")\n",
    "            print(f\"  Min: {param.min().item():.4f}\")\n",
    "            print(f\"  Max: {param.max().item():.4f}\")\n",
    "\n",
    "print(\"\\n=== Hardware Information ===\")\n",
    "devices = set(param.device for param in loaded_autoencoder.parameters())\n",
    "print(f\"Model Device(s): {devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this after loading the model\n",
    "for name, param in loaded_autoencoder.named_parameters():\n",
    "    if torch.isnan(param).any():\n",
    "        print(f\"Found NaN in {name}\")\n",
    "        print(f\"Number of NaN values: {torch.isnan(param).sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 1000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_offset_0</th>\n",
       "      <th>vertical_rate_0</th>\n",
       "      <th>ground_speed_0</th>\n",
       "      <th>heading_0</th>\n",
       "      <th>altitude_0</th>\n",
       "      <th>vertical_accel_0</th>\n",
       "      <th>ground_accel_0</th>\n",
       "      <th>turn_rate_0</th>\n",
       "      <th>climb_descent_accel_0</th>\n",
       "      <th>time_offset_1</th>\n",
       "      <th>...</th>\n",
       "      <th>time_offset_49</th>\n",
       "      <th>vertical_rate_49</th>\n",
       "      <th>ground_speed_49</th>\n",
       "      <th>heading_49</th>\n",
       "      <th>altitude_49</th>\n",
       "      <th>vertical_accel_49</th>\n",
       "      <th>ground_accel_49</th>\n",
       "      <th>turn_rate_49</th>\n",
       "      <th>climb_descent_accel_49</th>\n",
       "      <th>segment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021274</td>\n",
       "      <td>-2391.272217</td>\n",
       "      <td>426.204803</td>\n",
       "      <td>256.997345</td>\n",
       "      <td>26619.986328</td>\n",
       "      <td>-26.189440</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>0.608051</td>\n",
       "      <td>-103.790306</td>\n",
       "      <td>9.001877e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>400537216.0</td>\n",
       "      <td>-1286.003540</td>\n",
       "      <td>311.033478</td>\n",
       "      <td>280.729126</td>\n",
       "      <td>11123.783203</td>\n",
       "      <td>-0.198297</td>\n",
       "      <td>-0.271256</td>\n",
       "      <td>0.385261</td>\n",
       "      <td>17.207180</td>\n",
       "      <td>8776640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.027585</td>\n",
       "      <td>1309.264160</td>\n",
       "      <td>429.967102</td>\n",
       "      <td>16.964352</td>\n",
       "      <td>21088.099609</td>\n",
       "      <td>41.075996</td>\n",
       "      <td>-0.209062</td>\n",
       "      <td>0.446521</td>\n",
       "      <td>-16.958027</td>\n",
       "      <td>1.199074e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>750325632.0</td>\n",
       "      <td>-928.983521</td>\n",
       "      <td>456.485596</td>\n",
       "      <td>-3.226900</td>\n",
       "      <td>21995.623047</td>\n",
       "      <td>21.134535</td>\n",
       "      <td>0.320871</td>\n",
       "      <td>0.253475</td>\n",
       "      <td>-171.810287</td>\n",
       "      <td>9406275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010562</td>\n",
       "      <td>1091.447266</td>\n",
       "      <td>189.254166</td>\n",
       "      <td>222.599243</td>\n",
       "      <td>-3218.409912</td>\n",
       "      <td>22.040821</td>\n",
       "      <td>0.470975</td>\n",
       "      <td>0.090995</td>\n",
       "      <td>-63.672363</td>\n",
       "      <td>1.804085e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>148401136.0</td>\n",
       "      <td>1923.508545</td>\n",
       "      <td>256.459290</td>\n",
       "      <td>215.714081</td>\n",
       "      <td>8521.358398</td>\n",
       "      <td>-7.209484</td>\n",
       "      <td>-0.086521</td>\n",
       "      <td>-0.333846</td>\n",
       "      <td>-47.320778</td>\n",
       "      <td>9304767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000463</td>\n",
       "      <td>95.263321</td>\n",
       "      <td>462.243134</td>\n",
       "      <td>155.262802</td>\n",
       "      <td>34844.378906</td>\n",
       "      <td>-25.224617</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>0.203521</td>\n",
       "      <td>26.105040</td>\n",
       "      <td>1.976829e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>806281152.0</td>\n",
       "      <td>-296.389709</td>\n",
       "      <td>454.934967</td>\n",
       "      <td>145.074097</td>\n",
       "      <td>32942.191406</td>\n",
       "      <td>-17.680965</td>\n",
       "      <td>-0.037470</td>\n",
       "      <td>-0.131092</td>\n",
       "      <td>-71.101250</td>\n",
       "      <td>8865567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010340</td>\n",
       "      <td>36.086594</td>\n",
       "      <td>98.401344</td>\n",
       "      <td>8.072521</td>\n",
       "      <td>1492.007935</td>\n",
       "      <td>-9.836600</td>\n",
       "      <td>-0.388105</td>\n",
       "      <td>0.385285</td>\n",
       "      <td>10.416059</td>\n",
       "      <td>1.311079e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>431435712.0</td>\n",
       "      <td>-88.692192</td>\n",
       "      <td>92.438080</td>\n",
       "      <td>128.219528</td>\n",
       "      <td>1321.861450</td>\n",
       "      <td>-11.151931</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>0.035737</td>\n",
       "      <td>-127.268661</td>\n",
       "      <td>11002401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_offset_0  vertical_rate_0  ground_speed_0   heading_0    altitude_0  \\\n",
       "0       0.021274     -2391.272217      426.204803  256.997345  26619.986328   \n",
       "1      -0.027585      1309.264160      429.967102   16.964352  21088.099609   \n",
       "2       0.010562      1091.447266      189.254166  222.599243  -3218.409912   \n",
       "3      -0.000463        95.263321      462.243134  155.262802  34844.378906   \n",
       "4       0.010340        36.086594       98.401344    8.072521   1492.007935   \n",
       "\n",
       "   vertical_accel_0  ground_accel_0  turn_rate_0  climb_descent_accel_0  \\\n",
       "0        -26.189440        0.015159     0.608051            -103.790306   \n",
       "1         41.075996       -0.209062     0.446521             -16.958027   \n",
       "2         22.040821        0.470975     0.090995             -63.672363   \n",
       "3        -25.224617       -0.066722     0.203521              26.105040   \n",
       "4         -9.836600       -0.388105     0.385285              10.416059   \n",
       "\n",
       "   time_offset_1  ...  time_offset_49  vertical_rate_49  ground_speed_49  \\\n",
       "0   9.001877e+06  ...     400537216.0      -1286.003540       311.033478   \n",
       "1   1.199074e+07  ...     750325632.0       -928.983521       456.485596   \n",
       "2   1.804085e+06  ...     148401136.0       1923.508545       256.459290   \n",
       "3   1.976829e+07  ...     806281152.0       -296.389709       454.934967   \n",
       "4   1.311079e+07  ...     431435712.0        -88.692192        92.438080   \n",
       "\n",
       "   heading_49   altitude_49  vertical_accel_49  ground_accel_49  turn_rate_49  \\\n",
       "0  280.729126  11123.783203          -0.198297        -0.271256      0.385261   \n",
       "1   -3.226900  21995.623047          21.134535         0.320871      0.253475   \n",
       "2  215.714081   8521.358398          -7.209484        -0.086521     -0.333846   \n",
       "3  145.074097  32942.191406         -17.680965        -0.037470     -0.131092   \n",
       "4  128.219528   1321.861450         -11.151931         0.025553      0.035737   \n",
       "\n",
       "   climb_descent_accel_49  segment_id  \n",
       "0               17.207180     8776640  \n",
       "1             -171.810287     9406275  \n",
       "2              -47.320778     9304767  \n",
       "3              -71.101250     8865567  \n",
       "4             -127.268661    11002401  \n",
       "\n",
       "[5 rows x 451 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Examine outputs\n",
    "\n",
    "# read in sample data\n",
    "df = pd.read_parquet('../data/_09_autoencoder_training/results.parquet')\n",
    "\n",
    "print(f\"number of rows: {len(df)}\")\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDBScan\n",
    "\n",
    "Hyperparameters Chosen\n",
    "\n",
    "- Min Cluster Size (100)\n",
    "  - Currently represents ~0.1% of total dataset (100k samples)\n",
    "  - Initial choice targeted approximately 10 clusters\n",
    "  - Consider increasing to 250-500 for more robust clusters\n",
    "  - Larger clusters would better represent major flight patterns\n",
    "  \n",
    "- Min Samples (5)\n",
    "  - Conservative choice for noise detection\n",
    "  - Sufficient for statistical significance without being too restrictive\n",
    "  - Appropriate for normalized 10-dimensional space\n",
    "  - Balances between noise sensitivity and cluster stability\n",
    "\n",
    "- Epsilon (0.1)\n",
    "  - Suitable for normalized data in 10-dimensional space\n",
    "  - Conservative choice for allowing cluster expansion\n",
    "  - Works well with normalized autoencoder outputs\n",
    "  - Prevents excessive cluster merging\n",
    "\n",
    "- Euclidean Distance (metric choice)\n",
    "  - Natural choice for normalized, continuous flight data\n",
    "  - Performs well in moderate-dimensional spaces (10D)\n",
    "  - Computationally efficient for large datasets\n",
    "  - Intuitive distance measure for spatial patterns\n",
    "\n",
    "- EOM Cluster Selection\n",
    "  - Better than leaf for handling varying density clusters\n",
    "  - Well-suited for flight patterns that may have different densities\n",
    "  - More robust to noise than alternative methods\n",
    "  - Good at finding clusters of varying sizes\n",
    "\n",
    "Potential options for future research:\n",
    "\n",
    "- Min Cluster Size (currently 100)\n",
    "  - Try values: [250, 500, 750]\n",
    "  - Larger clusters would better represent major flight patterns\n",
    "  - Could reduce noise sensitivity\n",
    "  - May identify more stable, interpretable patterns\n",
    "\n",
    "- Min Samples (currently 5)\n",
    "  - Keep as is\n",
    "  - Well-tuned for current implementation\n",
    "  - Change only if noise sensitivity needs adjustment\n",
    "\n",
    "- Epsilon (currently 0.1)\n",
    "  - Keep as is\n",
    "  - Works well with normalized data\n",
    "  - Change only if cluster boundaries need adjustment\n",
    "\n",
    "- Alternative Metrics to Consider\n",
    "  - Cosine similarity for direction-based patterns\n",
    "  - Manhattan distance for computational efficiency\n",
    "  - Keep Euclidean as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Type: HDBSCAN\n",
      "Min Cluster Size: 10\n",
      "Cluster Selection Method: eom\n",
      "\n",
      "Number of clusters: 20\n",
      "Number of noise points: 337\n",
      "Total points: 860\n",
      "\n",
      "Cluster 0 size: 15\n",
      "\n",
      "Cluster 1 size: 41\n",
      "\n",
      "Cluster 2 size: 29\n",
      "\n",
      "Cluster 3 size: 33\n",
      "\n",
      "Cluster 4 size: 17\n",
      "\n",
      "Cluster 5 size: 27\n",
      "\n",
      "Cluster 6 size: 13\n",
      "\n",
      "Cluster 7 size: 10\n",
      "\n",
      "Cluster 8 size: 14\n",
      "\n",
      "Cluster 9 size: 20\n",
      "\n",
      "Cluster 10 size: 30\n",
      "\n",
      "Cluster 11 size: 15\n",
      "\n",
      "Cluster 12 size: 25\n",
      "\n",
      "Cluster 13 size: 16\n",
      "\n",
      "Cluster 14 size: 11\n",
      "\n",
      "Cluster 15 size: 18\n",
      "\n",
      "Cluster 16 size: 15\n",
      "\n",
      "Cluster 17 size: 11\n",
      "\n",
      "Cluster 18 size: 36\n",
      "\n",
      "Cluster 19 size: 127\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the pickled model\n",
    "with open('../data/_10_clustering/model.pkl', 'rb') as f:\n",
    "    clusterer = pickle.load(f)\n",
    "\n",
    "# Basic model info\n",
    "print(f\"Model Type: {type(clusterer).__name__}\")\n",
    "print(f\"Min Cluster Size: {clusterer.min_cluster_size}\")\n",
    "print(f\"Cluster Selection Method: {clusterer.cluster_selection_method}\")\n",
    "\n",
    "# Clustering results\n",
    "n_clusters = len(np.unique(clusterer.labels_)) - (1 if -1 in clusterer.labels_ else 0)\n",
    "print(f\"\\nNumber of clusters: {n_clusters}\")\n",
    "print(f\"Number of noise points: {np.sum(clusterer.labels_ == -1)}\")\n",
    "print(f\"Total points: {len(clusterer.labels_)}\")\n",
    "\n",
    "# Cluster sizes\n",
    "for label in np.unique(clusterer.labels_[clusterer.labels_ != -1]):\n",
    "    print(f\"\\nCluster {label} size: {np.sum(clusterer.labels_ == label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 21399\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>is_most_typical</th>\n",
       "      <th>is_most_extreme</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10648263</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9437118</th>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10669532</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10601579</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11968445</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cluster  is_most_typical  is_most_extreme\n",
       "segment_id                                           \n",
       "10648263          0            False            False\n",
       "9437118          -1            False            False\n",
       "10669532          0            False            False\n",
       "10601579          0            False            False\n",
       "11968445          0            False            False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Examine outputs\n",
    "\n",
    "# read in sample data\n",
    "df = pd.read_parquet('../data/_10_clustering/results.parquet').set_index('segment_id')\n",
    "\n",
    "print(f\"number of rows: {len(df)}\")\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
